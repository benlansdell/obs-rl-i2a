{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Environment Model\n",
    "\n",
    "Evaluate and visualize the performance of the environment model by seeing it visualize future states while a A2C agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from env_model_minigrid import make_env, create_env_model\n",
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "from common.minigrid_util import num_pixels, mode_rewards, pix_to_target, rewards_to_target\n",
    "from a2c import get_actor_critic, CnnPolicy\n",
    "from i2a import convert_target_to_real\n",
    "import gym\n",
    "import gym_minigrid\n",
    "import common.minigrid_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create the environments we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"MiniGrid-Blocks-6x6-v0\"\n",
    "nenvs = 16\n",
    "nsteps = 5\n",
    "envs = [make_env(env_name) for i in range(nenvs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "ob_space = envs.observation_space.shape\n",
    "ac_space = envs.action_space\n",
    "num_actions = envs.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, go ahead and test the environment model in minigrid. This will use the A2C agent to play the game and the environment model to predict future states and rewards. This will visualize the imagined and real rewards and game states from the environment model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation space (6, 6, 3)\n",
      "number of actions 5\n"
     ]
    }
   ],
   "source": [
    "#Make minigrid env...\n",
    "env = gym_minigrid.wrappers.ImgObsWrapper(gym.make(env_name))\n",
    "\n",
    "done = False\n",
    "states = env.reset()\n",
    "num_actions = ac_space.n\n",
    "nw, nh, nc = ob_space\n",
    "print('observation space', ob_space)\n",
    "print('number of actions', num_actions)\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lansdell/projects/o2a/o2a/a2c.py:61: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /home/lansdell/projects/o2a/o2a/a2c.py:14: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/lansdell/projects/o2a/o2a/a2c.py:16: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Restoring parameters from weights/a2c_100000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from weights/env_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_steps = 20\n",
    "pred_states = np.zeros((n_steps, nw, nh, nc))\n",
    "act_states = np.zeros((n_steps, nw, nh, nc))\n",
    "pred_rewards = np.zeros(n_steps)\n",
    "act_rewards = np.zeros(n_steps)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the actor\n",
    "    with tf.variable_scope('actor'):\n",
    "        actor_critic = get_actor_critic(sess, nenvs, nsteps, ob_space,\n",
    "                ac_space, CnnPolicy, should_summary=False)\n",
    "    actor_critic.load('weights/a2c_100000.ckpt')\n",
    "    \n",
    "    # Load the critic\n",
    "    with tf.variable_scope('env_model'): \n",
    "        env_model = create_env_model(ob_space, num_actions, num_pixels,\n",
    "                len(mode_rewards['regular']), should_summary=False)\n",
    "\n",
    "    save_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='env_model')\n",
    "    loader = tf.train.Saver(var_list=save_vars)\n",
    "    loader.restore(sess, 'weights/env_model.ckpt')\n",
    "    \n",
    "    while not done and steps < n_steps:\n",
    "        steps += 1\n",
    "        actions, _, _ = actor_critic.act(np.expand_dims(states, axis=0))\n",
    "\n",
    "        onehot_actions = np.zeros((1, num_actions, nw, nh))\n",
    "        onehot_actions[range(1), actions] = 1\n",
    "        # Change so actions are the 'depth of the image' as tf expects\n",
    "        onehot_actions = onehot_actions.transpose(0, 2, 3, 1)\n",
    "\n",
    "        s, r = sess.run([env_model.imag_state, \n",
    "                                        env_model.imag_reward], \n",
    "                                       feed_dict={\n",
    "                env_model.input_states: np.expand_dims(states, axis=0),\n",
    "                env_model.input_actions: onehot_actions\n",
    "            })\n",
    "        \n",
    "        s, r = convert_target_to_real(1, nw, nh, nc, s, r)\n",
    "        \n",
    "        states, reward, done, _ = env.step(actions[0])\n",
    "\n",
    "        pred_states[steps,:,:,:] = s[0]\n",
    "        act_states[steps,:,:,:] = states\n",
    "        pred_rewards[steps] = r\n",
    "        act_rewards[steps] = reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize...\n",
    "#for steps in range(n_steps-1,0,-1):\n",
    "for steps in range(n_steps):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.subplot(121)\n",
    "    plt.title(\"Step %d. Imagined (Reward %i)\" % (steps,pred_rewards[steps]))\n",
    "    plt.imshow(pred_states[steps,:,:,:]*11./255)\n",
    "    plt.subplot(122)\n",
    "        \n",
    "    plt.title(\"Actual (Reward %i)\" % act_rewards[steps])\n",
    "    plt.imshow(act_states[steps,:,:,:]*11./255)\n",
    "    plt.show()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weird thing with environment and reward dynamics... looks like x and y axes are being mixed somehow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
