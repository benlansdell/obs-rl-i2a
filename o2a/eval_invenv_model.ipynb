{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the inverse model\n",
    "\n",
    "Evaluate and visualize the performance of the environment model by seeing it visualize future states while a A2C agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't use the GPU for these runs:\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from inv_model_minigrid import make_env, create_env_model, create_latentinverse_env_model\n",
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "from common.minigrid_util import num_pixels, mode_rewards, pix_to_target, rewards_to_target\n",
    "from a2c import get_actor_critic, CnnPolicy\n",
    "from i2a import convert_target_to_real\n",
    "import gym\n",
    "import gym_minigrid\n",
    "import common.minigrid_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_to_str = {0:'D', 1:'R', 2:'U', 3:'L', 4:'N'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create the environments we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"MiniGrid-BlockMaze-v0\"\n",
    "#env_name = \"MiniGrid-Blocks-6x6-v0\"\n",
    "#env_name = \"MiniGrid-Blocks-8x8-v0\"\n",
    "#env_name = \"MiniGrid-Blocks-16x16-v0\"\n",
    "nenvs = 1\n",
    "nsteps = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, go ahead and test the environment model in minigrid. This will use the A2C agent to play the game and the environment model to predict future states and rewards. This will visualize the imagined and real rewards and game states from the environment model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 3)\n",
      "observation space (16, 16, 3)\n",
      "number of actions 5\n"
     ]
    }
   ],
   "source": [
    "#Make minigrid env...\n",
    "env = gym_minigrid.wrappers.ImgObsWrapper(gym.make(env_name))\n",
    "done = False\n",
    "states = env.reset()\n",
    "print(states.shape)\n",
    "num_actions = ac_space.n\n",
    "nw, nh, nc = ob_space\n",
    "print('observation space', ob_space)\n",
    "print('number of actions', num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from weights/a2c_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from weights/env_model_inverse.ckpt\n",
      "[2]\n",
      "Step: 0, Reward: -0.007812\n",
      "[3]\n",
      "Step: 1, Reward: -0.007812\n",
      "[0]\n",
      "Step: 2, Reward: -0.007812\n",
      "[3]\n",
      "Step: 3, Reward: -0.007812\n",
      "[0]\n",
      "Step: 4, Reward: -0.007812\n",
      "[1]\n",
      "Step: 5, Reward: -0.007812\n",
      "[2]\n",
      "Step: 6, Reward: -0.007812\n",
      "[1]\n",
      "Step: 7, Reward: -0.007812\n",
      "[0]\n",
      "Reached door!\n",
      "Step: 8, Reward: 1.000000\n",
      "[0]\n",
      "Step: 9, Reward: -0.007812\n",
      "[0]\n",
      "Step: 10, Reward: -0.007812\n",
      "[0]\n",
      "Step: 11, Reward: -0.007812\n",
      "[3]\n",
      "Step: 12, Reward: -0.007812\n",
      "[0]\n",
      "Step: 13, Reward: -0.007812\n",
      "[0]\n",
      "Step: 14, Reward: -0.007812\n",
      "[1]\n",
      "Step: 15, Reward: -0.007812\n",
      "[2]\n",
      "Step: 16, Reward: -0.007812\n",
      "[2]\n",
      "Step: 17, Reward: -0.007812\n",
      "[2]\n",
      "Reached door!\n",
      "Step: 18, Reward: 1.000000\n",
      "[2]\n",
      "Step: 19, Reward: -0.007812\n",
      "[2]\n",
      "Step: 20, Reward: -0.007812\n",
      "[3]\n",
      "Step: 21, Reward: -0.007812\n",
      "[2]\n",
      "Step: 22, Reward: -0.007812\n",
      "[2]\n",
      "Step: 23, Reward: -0.007812\n",
      "[1]\n",
      "Step: 24, Reward: -0.007812\n",
      "[0]\n",
      "Step: 25, Reward: -0.007812\n",
      "[0]\n",
      "Reached door!\n",
      "Step: 26, Reward: 1.000000\n",
      "[0]\n",
      "Step: 27, Reward: -0.007812\n",
      "[0]\n",
      "Step: 28, Reward: -0.007812\n",
      "[0]\n",
      "Step: 29, Reward: -0.007812\n",
      "[3]\n",
      "Step: 30, Reward: -0.007812\n",
      "[0]\n",
      "Step: 31, Reward: -0.007812\n",
      "[0]\n",
      "Step: 32, Reward: -0.007812\n",
      "[1]\n",
      "Step: 33, Reward: -0.007812\n",
      "[2]\n",
      "Step: 34, Reward: -0.007812\n",
      "[2]\n",
      "Step: 35, Reward: -0.007812\n",
      "[2]\n",
      "Reached door!\n",
      "Step: 36, Reward: 1.000000\n",
      "[2]\n",
      "Step: 37, Reward: -0.007812\n",
      "[2]\n",
      "Step: 38, Reward: -0.007812\n",
      "[3]\n",
      "Step: 39, Reward: -0.007812\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_steps = 40\n",
    "pred_actions = np.zeros((n_steps, num_actions))\n",
    "act_states = np.zeros((n_steps, nw, nh, nc))\n",
    "act_next_states = np.zeros((n_steps, nw, nh, nc))\n",
    "act_rewards = np.zeros(n_steps)\n",
    "act_actions = np.zeros(n_steps)\n",
    "steps = 0\n",
    "with tf.Session() as sess:\n",
    "    # Load the actor\n",
    "    with tf.variable_scope('actor'):\n",
    "        actor_critic = get_actor_critic(sess, nenvs, nsteps, ob_space,\n",
    "                ac_space, CnnPolicy, should_summary=False)\n",
    "    #actor_critic.load('weights/a2c_100000.ckpt')\n",
    "    actor_critic.load('weights/a2c_1000000.ckpt')\n",
    "\n",
    "    # Load the critic\n",
    "    with tf.variable_scope('env_model'):\n",
    "        env_model = create_latentinverse_env_model(ob_space, num_actions, num_pixels,\n",
    "                len(mode_rewards['regular']), should_summary=False)\n",
    "        #env_model = create_env_model(ob_space, num_actions, num_pixels,\n",
    "        #        len(mode_rewards['regular']), should_summary=False)\n",
    "\n",
    "    save_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='env_model')\n",
    "    loader = tf.train.Saver(var_list=save_vars)\n",
    "    loader.restore(sess, 'weights/env_model_inverse.ckpt')\n",
    "    \n",
    "    #while not done and steps < n_steps:\n",
    "    while steps < n_steps:\n",
    "        actions, _, _ = actor_critic.act(np.expand_dims(states, axis=0))\n",
    "        print(actions)\n",
    "        onehot_actions = np.zeros((1, num_actions))\n",
    "        onehot_actions[range(1), actions] = 1\n",
    "        next_states, reward, done, _ = env.step(actions[0])\n",
    "        ainv = sess.run([env_model.ainvprobs], \n",
    "                                       feed_dict={\n",
    "                env_model.input_states: np.expand_dims(states, axis=0),\n",
    "                env_model.target_states: np.expand_dims(next_states, axis = 0)\n",
    "            })\n",
    "        print(\"Step: %d, Reward: %f\"%(steps, reward))\n",
    "        pred_actions[steps,:] = ainv[0]\n",
    "        act_actions[steps] = actions[0]\n",
    "        act_states[steps,:,:,:] = states\n",
    "        act_next_states[steps,:,:,:] = next_states\n",
    "        act_rewards[steps] = reward\n",
    "        states = next_states\n",
    "        steps += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 0., 3., 0., 1., 2., 1., 0., 0., 0., 0., 3., 0., 0., 1., 2.,\n",
       "       2., 2., 2., 2., 3., 2., 2., 1., 0., 0., 0., 0., 0., 3., 0., 0., 1.,\n",
       "       2., 2., 2., 2., 2., 3.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_actions = np.argmax(pred_actions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_str = [act_to_str[i] for i in p_actions.tolist()]\n",
    "act_str = [act_to_str[i] for i in act_actions.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAADSCAYAAACo7W6xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEsJJREFUeJzt3Xu0XGV9xvHvk4QEiOEiwdRcalBTEFNATAUsYlpoBcQGrcuCYkl1rWgXKFgUIVaIl1a0Cmh1aRExuECpRVmmiEoWFSlFqASiXIKKkKuBACGQxCIEfv3jfSfsnH0uMydnZu8z83zWOuvM7L1n9m9f5pl37z3zjiICM7OiMVUXYGb142AwsxIHg5mVOBjMrMTBYGYlDgYzK3Ew1JCklZKOqbqOnSVprqS1VddhrRsyGCQdKekWSU9I2ijpfyT9SR43X9LN7SpO0mckrZH0pKRVkhb2Gf8mSXdL2pJrPLBdtdSVkk9Leiz/fVqSqq6rnSSFpJe3MH1b99N+5jcz1ziuDc+9SNIVLT6m5TeaQYNB0h7AtcC/Ai8EpgEfA37fykx2wteAAyJiD+C1wDskvSXXNgu4EngvsBfwn8CS4WyMdmzADs53AXAicDBwEPAm4D0j8Lw7qGodWUUiYsA/YA6waYBxrwCeAp4FtjSmAyYAnwVWAw8DXwF2y+PmAmuBhcCjwErgHYPVUJjfNOAu4Ox8/3Tg+4XxY4D/A45u8vlWAh8GfkEKunHAVOA7wCPAg8D787S75ueenO9/BNgG7JHvfwK4ON9+I3An8CSwBlhUmOdMIIB35/VzUx7+TmAV8Fh+7pXAMU0uxy3AgsL9dwO3NvnYRcDVwL8Dm4E7gIOHs47y9LsBi4HHgXuBDwFrB5n/5/M6ehJYBryuMG5s3k9+k2tbBswAbsrrcGve7/6mieWcD9zczDrp57H/ATwEPJHn/co+y/u5vO2eAG7Ow1bnGrfkvyP6ed7XAD8FNgHrgS8C4wvjXwksBTaSXkcLgWOBp4Fn8vP+vIV9van9aftjhnjCPfLOejlwHLD3UCscuAhYQmphTCK9k3+qEAzbgAtJAfL6vIH3H6SGc/JKCOABYHohGK7rsyM9BZzRwspanne23UjBsgw4DxgPvDTP7w15+puAv863r8877HGFcW8uLOMf5+c7KG/UE/sEwzeAiXm+B+blOyqvkwvzOjomP+ZIBgjnPP4J4LDC/TnA5haC4RngrcAuwAdJL/ZdhrmOLgD+O2/7GcDdDB4MpwD7kALnLNILcNc87kOkN4L9AZFaRPvkcQG8vM9zbQKObEMwvIu0H08ALgaWF8Z9CbiR9KY1ltSqnVDYzuMGed5XA4fnZZ8JrADOzOMmkcLiLNKb0qTGNs7b7Ip+XiPXdiwY8pO+gvQusDbvsEuAKf2t8LwBtwIvKww7AniwTzBMLIz/NvDRIWoQ8CrSYcykPOyAPK+5eSf9KPAccG4LwfCuwv3DgNV9pjkX+Hq+/QngC3lDPgScQXohNFoT+wwwn4uBi/oEw0sL488Drircn0h6V2i2xfAs6XCrcX9WnoeaeOwiCq0L0gt/Pfmdexjr6AHg2MK4BQwSDP3U8zi5xQL8Epg3wHSlYBjieXfYT4f7RzpkDWBPnm+hHtzPdI3tPGAw9POYM4Fr8u2TgTsH2WZXtFj3ymb3p8bfkCcfI2JFRMyPiOnAbFJT8uIBJt8X2B1YJmmTpE3AD/PwhscjYmvh/qr8nIPVEBFxZ94QH8vD7gNOJTXB1gOTSc3XVs6CryncfgkwtVF3rn0hMCWP/wkphA4lvZMtJbV4Dgfuj4jHACQdJunHkh6R9ATpHMjkQeY7tXg/r5vHWliGLaSWXcMewJbIe0QTivN+jrT+pvY3nqHX0dQ+068abMaSPihpRT6xvYn0gmusqxmkVlllJI2VdIGk30h6kvQCg1TjZNKbwrBqlPRHkq6V9FB+7n+mRsve0uXK/GJcTAoISKlY9CjpxfvKiNgr/+0ZES8oTLO3pImF+38I/LbJEsYBLyvUc3VEzI6IfYDzSUn9s2aXp0/9a0gtm70Kf5Mi4vg8/hZSs/bNwE8i4t5c+/Gk0Gj4JqlVNSMi9iSdY+l7laA43/WkHQEASbuTmtfNuofUzG44OA9rVnHeY4Dp7Lg9WllHOywLaf30S9LrgLOBt5EOUfciHRY11tUaCtu6Im8H5gHHkEJrZh4u0r7+FP3X2Ewofxm4D5gV6eT6QnZc9pcO8LiOfB16qKsSB0g6S9L0fH8GqZlza57kYWC6pPGw/R3nq8BFkl6UHzNN0hv6PPXHJI3PO8cJpBM8fec9RtJ7JO2dL8m9BjgNuKEwzatzqu8LXAIsyeE1HP8LbJb0YUm75eed3bg0GxG/Ix1fn8bzQXALqUVQDIZJwMaIeCrX/PYh5ns1cEK+LDwe+DitBfY3gH/I63kq6bh0cWNkvlQ1f5DHv1rSW/JVhzNJJxlvHWDaQdcR6bDw3LzNpgPvG2S+k0iHlY8A4ySdx44tn0uBT0ialbf/QZIagfkwA79wBiJJuxb/8sBFkm4cpMbfk1pwu5Pe1YHt+/plwIWSpuZ1cYSkCXmZnhuixkmkk65bJB0A/H1h3LXAiyWdKWmCpEmSDiss+8wc4q3Ypc/yD36VaYhjk2mkjb2OdDy/Dvg3nj8bPx74PunM6aN52K6kFfhAXvAVPH92fy6pqfoRUuKuBt45wLzHkA5DNpKay78ip2phmptJZ6w35rqK5y7eAdzTynEXqSn8LdI5hMdJL5BjCuM/RWoRTcj3Tycl+JTCNG8lNaE3kzbwF8nHhAxw7Ek6JFpNP1clgNeRDg0GWg4Bn8nrYGO+rcL22UzhHEQ/x6vFqxJ3AocOdx2RXjzfIJ0IHPSqBOlk3WV5H1lPaj0Ul3ss8I+kk6GbSS3Bxonn9+bHbALelodtoXBVo8+85uf13vdvHOmS+D8N8LgXAN/L818F/C2F8xukE7IXk14XjasWjStwHycFxCbg8H6e+yhSi2EL6YTtx9nxfN1s0pvg43ldn5OH70Pa7x8H7sjDFgI/GGJf77vsnxzstd/YgTpC0lzSi2R6x2bawyQdCZwWEScPMH4RaSc/paOF1Yik5aRL3K2c1+l6/tBKF4uIm0nvLjaAiDik6hrqyN+VMLOSjh5KmNno4BaDmZU4GMyspCtOPmoXxZgJVVdhljy3lUcjYt+hp6yv2gaDpGNJ374bC1waERcMNO2YCbDb7IHGmnXW1tsG/yj4aFDLQwlJY0nfXDuO9O3Dk9WDnbCYVaWWwUD6rvr9EfFARDwNXEX6zLqZdUBdg2EaO35Lb20eZmYdUNtzDEORtID0fX/SV7jMbKTUtcWwjh2/vjs9D9suIi6JiDkRMUe7dLQ2s65X12D4GTBL0n75q8gnkfo4MLMOqOWhRERsk3Q68CPy13MjopXOR8xsJ9QyGAAi4jrgupF8zq23jeSztWbiYUNPA9XWONKaXWYYHcvdyvKMdnU9lDCzCjkYzKzEwWBmJQ4GMytxMJhZiYPBzEocDGZW4mAwsxIHg5mV1PaTj6PF+5uc7guj4JN9Zg1uMZhZiYPBzEpqGQySZkj6saR7Jd0j6YyqazLrJXU9x7ANOCsi7pA0CVgmaWlE3Ft1YWa9oJYthohYHxF35NubgRW4z0ezjqlri2E7STOBVwG39RnuPh/N2qSWLYYGSS8AvgOcGRFPFse5z0ez9qltMEjahRQKV0bEd6uux6yX1DIYJAn4GrAiIi6suh6zXlPLYAD+FHgn8OeSlue/46suyqxX1PLkY0TcDKiq+Z/7ouan/dSG5qbrxc5gbfSqa4vBzCrkYDCzEgeDmZU4GMysxMFgZiUOBjMrcTCYWYmDwcxKHAxmVlLLTz62S7OfPvxCC8+534aJTU23ga1NTdeOn1r3pymtVW4xmFlJrYNB0lhJd0q6tupazHpJrYMBOIPUrZuZdVBtg0HSdOCNwKVV12LWa2obDMDFwNnAc1UXYtZrahkMkk4ANkTEskGmWSDpdkm3xzMdLM6sB9QyGEg9OP2VpJXAVaSenK4oTuDOYM3ap5bBEBHnRsT0iJgJnAT8V0ScUnFZZj2jlsFgZtWq/ScfI+JG4MZOzrOVTwo+2OQnGhnhTx+24xOSZg1uMZhZiYPBzEocDGZW4mAwsxIHg5mVOBjMrMTBYGYlDgYzK3EwmFlJ7T/5aP1zP47WTm4xmFlJbYNB0l6SrpZ0n6QVko6ouiazXlHnQ4nPAz+MiLdKGg/sXnVBZr2ilsEgaU/gKGA+QEQ8DTxdZU1mvaSuhxL7AY8AX8/dx18qqblfdjGznVbXYBgHHAp8OSJeBWwFzilO4D4fzdqnrsGwFlgbEY2LcleTgmI79/lo1j61DIaIeAhYI2n/POho4N4KSzLrKbU8+Zi9D7gyX5F4APi7iusx6xm1DYaIWA7MqboOs15U22CwwbXSGaw/Pm2tquU5BjOrloPBzEocDGZW4mAwsxIHg5mVOBjMrMTBYGYlDgYzK3EwmFmJP/nYIRc12ZvEB7a2tw6zZrjFYGYltQ0GSR+QdI+kuyV9S9KuVddk1itqGQySpgHvB+ZExGxgLHBStVWZ9Y5aBkM2DthN0jhSD9G/rbges55Ry2CIiHXAZ4HVwHrgiYi4vjiN+3w0a59aBoOkvYF5pN6ipwITJZ1SnMZ9Ppq1Ty2DATgGeDAiHomIZ4DvAq+tuCaznlHXYFgNHC5pd0kidQa7ouKazHpGLYMhdxt/NXAHcBepzksqLcqsh9T2k48RcT5wftV1jBR/otFGk1q2GMysWg4GMytxMJhZiYPBzEocDGZW4mAwsxIHg5mVOBjMrMTBYGYltf3kY5Va+SXp0aDblsfazy0GMyupNBgkXSZpg6S7C8NeKGmppF/n/3tXWaNZL6q6xbAYOLbPsHOAGyJiFnBDvm9mHVRpMETETcDGPoPnAZfn25cDJ3a0KDOrvMXQnykRsT7ffgiYUmUxZr2o1lclIiIkRX/jJC0AFgBofEfLMut6dWwxPCzpxQD5/4b+JnJnsGbtU8dgWAKcmm+fCnyvwlrMelLVlyu/BfwU2F/SWknvBi4A/kLSr0m9RV9QZY1mvajScwwRcfIAo47uaCFmtoNan3wcaVtvq7oCs9GhjucYzKxiDgYzK3EwmFmJg8HMShwMZlbiYDCzEgeDmZU4GMysxMFgZiUOBjMrcTCYWUnV367srzPYf5F0n6RfSLpG0l5V1mjWi6puMSym3BnsUmB2RBwE/Ao4t9NFmfW62nUGGxHXR8S2fPdWYHrHCzPrcVW3GIbyLuAH/Y2QtEDS7ZJuj2c6XJVZl6ttMEj6CLANuLK/8e7z0ax9atlRi6T5wAnA0RHRby/RZtY+tQsGSccCZwOvj4jfVV2PWS+q+nJlf53BfhGYBCyVtFzSV6qs0awX1bEz2K91vBAz20FtTz6aWXUcDGZW4mAwsxIHg5mVOBjMrMTBYGYlDgYzK3EwmFmJg8HMShwMZlbiYDCzkqq/RFXq87Ew7ixJIWlyFbWZ9bKqWwyLKff5iKQZwF8CqztdkJnVsM/H7CJSnwzupMWsAlW3GEokzQPWRcTPq67FrFfVqgcnSbsDC0mHEUNNuwBYAKDxbS7MrMfUrcXwMmA/4OeSVpK6jr9D0h/0ndCdwZq1T61aDBFxF/Cixv0cDnMi4tHKijLrQVVfruyvz0czq1gd+3wsjp/ZoVLMrKBWhxLtNvGwqiswGx3qdvLRzGrAwWBmJQ4GMytxMJhZiYPBzEocDGZW4mAwsxIHg5mVOBjMrEQRo78vFEmPAKv6GTUZ6JYvYHXLsnTLcsDAy/KSiNi308WMpK4IhoFIuj0i5lRdx0jolmXpluWA7lqWvnwoYWYlDgYzK+n2YLik6gJGULcsS7csB3TXsuygq88xmNnwdHuLwcyGoSuDQdKxkn4p6X5J51Rdz86QtFLSXZKWS7q96npa0d8vjUl6oaSlkn6d/+9dZY3NGmBZFklal7fNcknHV1njSOq6YJA0FvgScBxwIHCypAOrrWqn/VlEHDIKL40tpvxLY+cAN0TELOCGfH80WEw/v5oGXJS3zSERcV2Ha2qbrgsG4DXA/RHxQEQ8DVwFzKu4pp40wC+NzQMuz7cvB07saFHDNMivpnWlbgyGacCawv21edhoFcD1kpblH9kZ7aZExPp8+yFgSpXFjIDTJf0iH2qMisOiZnRjMHSbIyPiUNKh0WmSjqq6oJES6ZLYaL4s9mXSjyQdAqwHPldtOSOnG4NhHTCjcH96HjYqRcS6/H8DcA3pUGk0e1jSiwHy/w0V1zNsEfFwRDwbEc8BX2X0b5vtujEYfgbMkrSfpPHAScCSimsaFkkTJU1q3Cb9pufdgz+q9pYAp+bbpwLfq7CWndIIuOzNjP5ts13X/a5ERGyTdDrwI2AscFlE3FNxWcM1BbhGEqRt9c2I+GG1JTUv/9LYXGCypLXA+cAFwLfzr46tAt5WXYXNG2BZ5ko6hHQ4tBJ4T2UFjjB/8tHMSrrxUMLMdpKDwcxKHAxmVuJgMLMSB4OZlTgYzKzEwWBmJQ4GMyv5fyKr3Pv1KwWcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize...\n",
    "#If it goes blank then reached the done state\n",
    "for steps in range(n_steps):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(10,3))        \n",
    "    plt.title(\"Step %d. reward: %i, pred act: %s, act act: %s\" % (steps,act_rewards[steps], pred_str[steps], act_str[steps]))\n",
    "    plt.imshow(act_next_states[steps,:,:,:]*11./255)\n",
    "    plt.show()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
